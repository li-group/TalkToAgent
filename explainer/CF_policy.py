import traceback
import numpy as np
from src.pcgym import make_env

from params import running_params, env_params

from sub_agents.Policy_generator import PolicyGenerator
from sub_agents.Debugger import Debugger

running_params = running_params()
env, env_params = env_params(running_params['system'])

def cf_by_policy(t_begin, t_end, policy, message, team_conversation, max_retries, horizon):
    """
    Counterfactual analysis to future trajectories, according to rule-based policies.
    The policies are generated by successive interactions with coder and evaluator agent.
    i.e.) "What would the trajectory change if I use the bang-bang controller instead of the current RL policy?"
          "Why don't we just use the PID controller instead of the RL policy?"
          "Would you compare the predicted trajectory between our RL policy and bang-bang controller after t-300?"
    """

    begin_index = int(np.round(t_begin / env_params['delta_t']))
    end_index = int(np.round(t_end / env_params['delta_t']))
    horizon += end_index - begin_index # Re-adjusting horizon

    env_params['noise'] = False  # For reproducibility
    env = make_env(env_params)

    # Regenerating trajectory data with noise disabled
    evaluator, data = env.get_rollouts({'Actual': policy}, reps=1, get_Q=True)

    generator = PolicyGenerator()
    debugger = Debugger()

    # Generate policy
    CF_policy, code = generator.generate(message, policy)
    print(f"[PolicyGenerator] Initial counterfactual policy generated")
    team_conversation.append({"agent": "PolicyGenerator", "summary": f"Initial policy generated", "full_content": generator.prev_codes[-1]})

    success = False
    attempt = 0

    while not success and attempt < max_retries:
        try:
            # Running the simulation with counterfactual policy
            cf_settings = {
                'CF_mode': 'policy',
                'begin_index': begin_index,
                'end_index': end_index,
                'CF_policy': CF_policy
            }
            _, data_cf = env.get_rollouts({'New policy': policy}, reps=1, get_Q=False,
                                                  cf_settings=cf_settings)
            success = True

        except Exception as e:
            attempt += 1
            error_message = traceback.format_exc()

            guidance = debugger.debug(code, error_message)

            print(f"[Evaluator] Error during rollout (attempt {attempt}):\n{error_message}")
            team_conversation.append({"agent": "Evaluator", "full_content": f"Error during rollout (attempt {attempt}):\n{error_message}"
                                      })

            # CF_policy = generator.refine(error_message)
            CF_policy = generator.refine_new(error_message, guidance)
            team_conversation.append({"agent": "PolicyGenerator", "summary": f"CF policy refined",
                                      "full_content": generator.prev_codes[-1]})

    print("[Evaluator] Code successfully generated. Rollout complete." if success else "[Evaluator] Failed after multiple attempts.")

    if success:
        # Append counterfactual results to evaluator object
        evaluator.n_pi += 1
        evaluator.policies['New policy'] = policy
        evaluator.data = data | data_cf

        for al, traj in evaluator.data.items():
            for k, v in traj.items():
                evaluator.data[al][k] = v[:, begin_index - 1:begin_index + horizon, :]
        interval = [begin_index - 1, begin_index + horizon]  # Interval to watch the control results

        figures = [evaluator.plot_data(evaluator.data, interval=interval)]
        return figures